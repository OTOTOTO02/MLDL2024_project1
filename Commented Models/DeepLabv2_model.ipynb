{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P8voc4W-7P1F"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "affine_par = True\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "  # how does it work? Imagine you want to process a feature map with 256 channels. Instead of applying a \"big\" convolution from 256 to 256 (which is computationally expensive),\n",
        "  # the bottleneck does this: 1) Reduces the number of channels (e.g., from 256 → 64) → less data to process 2)  Processes those fewer channels\n",
        "  # 3) Expands the channels back to the original size (from 64 → 256) 4) Adds the original input to the final result (skip connection).\n",
        "  # In this way it learns a lot, even if it is working in a smaller size.\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, dilation=1, downsample=None): #inplanes and planes are the number of channels\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, stride=stride, bias=False) # here the compression happens\n",
        "        self.bn1 = nn.BatchNorm2d(planes, affine=affine_par) #it normalizes values obtained in the middle hidden layers to make the algorithm more stable.\n",
        "        #affine is used to include or not in the normalization of values the learned parameters gamma and beta.\n",
        "        for i in self.bn1.parameters():\n",
        "            i.requires_grad = False #it unables the gradient for the parameters of the batch normalization level. It means that those parameters won't be updated\n",
        "            # (i.e. learned) by the model during training phase (those parameters are beta and gamma)\n",
        "        padding = dilation\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1,\n",
        "                               padding=padding, bias=False, dilation=dilation)\n",
        "        self.bn2 = nn.BatchNorm2d(planes, affine=affine_par)\n",
        "        for i in self.bn2.parameters():\n",
        "            i.requires_grad = False\n",
        "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False) # here the expansion happens\n",
        "        self.bn3 = nn.BatchNorm2d(planes * 4, affine=affine_par)\n",
        "        for i in self.bn3.parameters():\n",
        "            i.requires_grad = False\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x): #it is the method called in order to work with the input and obtain an output\n",
        "        residual = x # store the original input in residual\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "        if self.downsample is not None: #if the out has different size from residual\n",
        "            residual = self.downsample(x) #then, adapt residual to out's size\n",
        "        out += residual # basically residual is added to out in order to understand how to modify the input in order to obtain a better prediction\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ClassifierModule(nn.Module):\n",
        "    def __init__(self, inplanes, dilation_series, padding_series, num_classes): #dilation_series and padding_series are lists of values for dilation and padding in the\n",
        "    #convolutional layers\n",
        "    #the dilation parameter is equal to the number of holes in the kernel (atrous)\n",
        "        super(ClassifierModule, self).__init__()\n",
        "        self.conv2d_list = nn.ModuleList() # a list of convolutional layers\n",
        "        for dilation, padding in zip(dilation_series, padding_series): #it is creating parallel convolutions with different values of dilation (useful for ASPP).\n",
        "            self.conv2d_list.append(\n",
        "                nn.Conv2d(inplanes, num_classes, kernel_size=3, stride=1, padding=padding,\n",
        "                          dilation=dilation, bias=True))\n",
        "\n",
        "        for m in self.conv2d_list:\n",
        "            m.weight.data.normal_(0, 0.01)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv2d_list[0](x)\n",
        "        for i in range(len(self.conv2d_list) - 1): #the maps (che sono l'output dei diversi branch convoluzionali paralleli) all have the same size if the paddings\n",
        "        # are chosen correctly according to dilation\n",
        "            out += self.conv2d_list[i + 1](x) # the features extracted are fused to generate the final result\n",
        "        #the feature maps obtained for each type of kernel have different fields of view. Therefore, when we concatenate them, we will have information of a local and global context\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNetMulti(nn.Module): #it is the modification of ResNet to obtain DeepLab.\n",
        "    def __init__(self, block, layers, num_classes):\n",
        "        self.inplanes = 64\n",
        "        super(ResNetMulti, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64, affine=affine_par)\n",
        "        for i in self.bn1.parameters():\n",
        "            i.requires_grad = False\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1, ceil_mode=True)  # change\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        # up to layer2 we have a downsampling phase, where we are aquiring knowledge about what is represented (semantic). Then, with layer 3 and 4 we are using kernels with larger\n",
        "        # receptieve fields in order to improve the spatial density.\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=1, dilation=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=1, dilation=4)\n",
        "        # the layer6 is used to apply ASPP in order to have multiscale image representations\n",
        "        self.layer6 = ClassifierModule(2048, [6, 12, 18, 24], [6, 12, 18, 24], num_classes)\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                m.weight.data.normal_(0, 0.01)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1, dilation=1):\n",
        "      # make_layer is used to build a stack of residual blocks.\n",
        "      # - block is the type of residual block (e.g. BottleNeck)\n",
        "      # - planes = number of output channels before expansion\n",
        "      # - blocks = how many residual blocks to stack\n",
        "      # - stride = used for spatial downsampling\n",
        "      # - dilation = used for dilated convolutions\n",
        "        downsample = None\n",
        "        if (stride != 1\n",
        "                or self.inplanes != planes * block.expansion\n",
        "                or dilation == 2\n",
        "                or dilation == 4): # if the feature maps are going to change the size, then we need to downsample in order to add the input to the output block\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion, affine=affine_par))\n",
        "        for i in downsample._modules['1'].parameters():\n",
        "            i.requires_grad = False\n",
        "        layers = []\n",
        "        layers.append(\n",
        "            block(self.inplanes, planes, stride, dilation=dilation, downsample=downsample))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes, dilation=dilation))\n",
        "        # it basically returns a list of BottleNeck blocks.\n",
        "        # The Bottleneck does the same work as a chain of standard convolutional layers, but it does it in a smarter and more efficient way,\n",
        "        # making it possible to build much deeper networks without exploding in parameters or computations.\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        _, _, H, W = x.size()\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.layer6(x)\n",
        "\n",
        "        x = torch.nn.functional.interpolate(x, size=(H, W), mode='bilinear')\n",
        "        # Because the output from the deep layers is smaller than the input image (due to downsampling),\n",
        "        # we resize it back to match the original input size using bilinear interpolation.\n",
        "        if self.training == True:\n",
        "            return x, None, None\n",
        "\n",
        "        return x\n",
        "\n",
        "    def get_1x_lr_params_no_scale(self):\n",
        "        \"\"\"\n",
        "        This generator returns all the parameters of the net except for\n",
        "        the last classification layer. Note that for each batchnorm layer,\n",
        "        requires_grad is set to False in deeplab_resnet.py, therefore this function does not return\n",
        "        any batchnorm parameter\n",
        "        \"\"\"\n",
        "        b = []\n",
        "\n",
        "        b.append(self.conv1)\n",
        "        b.append(self.bn1)\n",
        "        b.append(self.layer1)\n",
        "        b.append(self.layer2)\n",
        "        b.append(self.layer3)\n",
        "        b.append(self.layer4)\n",
        "\n",
        "        for i in range(len(b)):\n",
        "            for j in b[i].modules():\n",
        "                jj = 0\n",
        "                for k in j.parameters():\n",
        "                    jj += 1\n",
        "                    if k.requires_grad:\n",
        "                        yield k\n",
        "\n",
        "    def get_10x_lr_params(self):\n",
        "        \"\"\"\n",
        "        This generator returns all the parameters for the last layer of the net,\n",
        "        which does the classification of pixel into classes\n",
        "        \"\"\"\n",
        "        b = []\n",
        "        if self.multi_level:\n",
        "            b.append(self.layer5.parameters())\n",
        "        b.append(self.layer6.parameters())\n",
        "\n",
        "        for j in range(len(b)):\n",
        "            for i in b[j]:\n",
        "                yield i\n",
        "\n",
        "    def optim_parameters(self, lr):\n",
        "        return [{'params': self.get_1x_lr_params_no_scale(), 'lr': lr},\n",
        "                {'params': self.get_10x_lr_params(), 'lr': 10 * lr}]\n",
        "\n",
        "\n",
        "def get_deeplab_v2(num_classes=19, pretrain=True, pretrain_model_path='DeepLab_resnet_pretrained_imagenet.pth'):\n",
        "    # This function returns a DeepLabV2-like model with a ResNet-101 backbone, and optionally loads pretrained weights.\n",
        "    # num_classes: Number of classes for segmentation (default = 19, for example Cityscapes dataset)\n",
        "    # pretrain: Whether to load pretrained weights\n",
        "    # pretrain_model_path: Path to the pretrained weights file\n",
        "    model = ResNetMulti(Bottleneck, [3, 4, 23, 3], num_classes)\n",
        "\n",
        "    # Pretraining loading\n",
        "    if pretrain:\n",
        "        print('Deeplab pretraining loading...')\n",
        "        saved_state_dict = torch.load(pretrain_model_path)\n",
        "\n",
        "        new_params = model.state_dict().copy()\n",
        "        for i in saved_state_dict:\n",
        "            i_parts = i.split('.')\n",
        "            new_params['.'.join(i_parts[1:])] = saved_state_dict[i]\n",
        "        model.load_state_dict(new_params, strict=False)\n",
        "    return model # Now the model is ready — with or without pretrained weights. The pretrained weights give an initial advantage for the training phase."
      ]
    }
  ]
}